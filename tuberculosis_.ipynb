{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/losirlu1411/project-/blob/main/tuberculosis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ukBVUkPFOjbO"
      },
      "outputs": [],
      "source": [
        "### 1. Imports and Configuration\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import Recall\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.applications import VGG16, DenseNet201, ResNet101\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ck1jrFc5OpCQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dataset path\n",
        "base_path = '/content/drive/MyDrive/project /TB_Chest_Radiography_Database'\n",
        "\n",
        "# Class labels\n",
        "labels = ['Normal', 'Tuberculosis']\n",
        "image_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 2. Data Loading and Preprocessing\n",
        "# Function to load and preprocess images with optional sampling\n",
        "def load_data(base_path, labels, image_size, sample_size=None):\n",
        "    data, label_list = [], []\n",
        "    for label_idx, label in enumerate(labels):\n",
        "        folder_path = os.path.join(base_path, label)\n",
        "        all_files = os.listdir(folder_path)\n",
        "        if sample_size:\n",
        "            sampled_files = random.sample(all_files, min(len(all_files), sample_size))\n",
        "        else:\n",
        "            sampled_files = all_files\n",
        "        for file_name in sampled_files:\n",
        "            img_path = os.path.join(folder_path, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            data.append(img)\n",
        "            label_list.append(label_idx)\n",
        "    return np.array(data), np.array(label_list)\n",
        "\n",
        "# Load dataset with all samples\n",
        "print(\"Loading full dataset...\")\n",
        "x_data_full, y_data_full = load_data(base_path, labels, image_size)\n",
        "x_data_full = x_data_full / 255.0  # Normalize images\n",
        "y_data_full = to_categorical(y_data_full, num_classes=len(labels))  # One-hot encode labels\n",
        "print(f\"Total images loaded: {len(x_data_full)}\")\n",
        "# Load dataset with 500 samples per class\n",
        "print(\"Loading sampled dataset (500 per class)...\")\n",
        "x_data_sampled, y_data_sampled = load_data(base_path, labels, image_size, sample_size=500)\n",
        "x_data_sampled = x_data_sampled / 255.0  # Normalize images\n",
        "y_data_sampled = to_categorical(y_data_sampled, num_classes=len(labels))  # One-hot encode labels\n",
        "print(f\"Total images loaded: {len(x_data_sampled)}\")\n",
        "# Split into train and test sets for both datasets\n",
        "x_train_full, x_test_full, y_train_full, y_test_full = train_test_split(x_data_full, y_data_full, test_size=0.2, random_state=42)\n",
        "x_train_sampled, x_test_sampled, y_train_sampled, y_test_sampled = train_test_split(x_data_sampled, y_data_sampled, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpES4tSkc6d7",
        "outputId": "2a4015c3-9f84-4455-b55f-77f5803ca936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading full dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 3. Class Weights and Data Augmentation\n",
        "# Compute class weights for both datasets\n",
        "class_weights_full = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(np.argmax(y_train_full, axis=1)),\n",
        "    y=np.argmax(y_train_full, axis=1)\n",
        ")\n",
        "class_weights_sampled = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(np.argmax(y_train_sampled, axis=1)),\n",
        "    y=np.argmax(y_train_sampled, axis=1)\n",
        ")\n",
        "class_weights_dict_full = {i: weight for i, weight in enumerate(class_weights_full)}\n",
        "class_weights_dict_sampled = {i: weight for i, weight in enumerate(class_weights_sampled)}\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "train_datagen.fit(x_train_full)\n",
        "train_datagen.fit(x_train_sampled)"
      ],
      "metadata": {
        "id": "gIlvhqv6VUUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 4. Model Building\n",
        "# Function to build a custom CNN model\n",
        "def build_custom_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "        metrics=['accuracy', Recall(class_id=1, name=\"recall\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Function to build pretrained models\n",
        "def build_pretrained_model(base_model, input_shape, num_classes):\n",
        "    base_model.trainable = False\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "        metrics=['accuracy', Recall(class_id=1, name=\"recall\")]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "fg8N44USVWVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 5. Training and Evaluation Framework\n",
        "# Function to train and evaluate model\n",
        "def train_and_evaluate_model(model, model_name, x_train, y_train, x_test, y_test, datagen, class_weights):\n",
        "    print(f\"Training {model_name}...\")\n",
        "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        datagen.flow(x_train, y_train, batch_size=32),\n",
        "        validation_data=(x_test, y_test),\n",
        "        epochs=20,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    y_pred_probs = model.predict(x_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "    print(f\"Classification Report for {model_name}:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=labels))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "    return history"
      ],
      "metadata": {
        "id": "Lo0KbyemXNP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 6. Model Training\n",
        "# Define input shape and number of classes\n",
        "input_shape = (image_size, image_size, 3)\n",
        "num_classes = len(labels)\n",
        "\n",
        "# Custom Model\n",
        "custom_model_full = build_custom_model(input_shape, num_classes)\n",
        "custom_history_full = train_and_evaluate_model(custom_model_full, \"Custom CNN (Full Dataset)\", x_train_full, y_train_full, x_test_full, y_test_full, train_datagen, class_weights_dict_full)\n",
        "\n",
        "custom_model_sampled = build_custom_model(input_shape, num_classes)\n",
        "custom_history_sampled = train_and_evaluate_model(custom_model_sampled, \"Custom CNN (Sampled Dataset)\", x_train_sampled, y_train_sampled, x_test_sampled, y_test_sampled, train_datagen, class_weights_dict_sampled)\n",
        "\n",
        "# VGG16\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "vgg16_model_full = build_pretrained_model(vgg16_base, input_shape, num_classes)\n",
        "vgg16_history_full = train_and_evaluate_model(vgg16_model_full, \"VGG16 (Full Dataset)\", x_train_full, y_train_full, x_test_full, y_test_full, train_datagen, class_weights_dict_full)\n",
        "\n",
        "vgg16_model_sampled = build_pretrained_model(vgg16_base, input_shape, num_classes)\n",
        "vgg16_history_sampled = train_and_evaluate_model(vgg16_model_sampled, \"VGG16 (Sampled Dataset)\", x_train_sampled, y_train_sampled, x_test_sampled, y_test_sampled, train_datagen, class_weights_dict_sampled)\n",
        "\n",
        "# DenseNet201\n",
        "densenet_base = DenseNet201(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "densenet_model_full = build_pretrained_model(densenet_base, input_shape, num_classes)\n",
        "densenet_history_full = train_and_evaluate_model(densenet_model_full, \"DenseNet201 (Full Dataset)\", x_train_full, y_train_full, x_test_full, y_test_full, train_datagen, class_weights_dict_full)\n",
        "\n",
        "densenet_model_sampled = build_pretrained_model(densenet_base, input_shape, num_classes)\n",
        "densenet_history_sampled = train_and_evaluate_model(densenet_model_sampled, \"DenseNet201 (Sampled Dataset)\", x_train_sampled, y_train_sampled, x_test_sampled, y_test_sampled, train_datagen, class_weights_dict_sampled)\n",
        "\n",
        "# ResNet101\n",
        "resnet_base = ResNet101(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "resnet_model_full = build_pretrained_model(resnet_base, input_shape, num_classes)\n",
        "resnet_history_full = train_and_evaluate_model(resnet_model_full, \"ResNet101 (Full Dataset)\", x_train_full, y_train_full, x_test_full, y_test_full, train_datagen, class_weights_dict_full)\n",
        "\n",
        "resnet_model_sampled = build_pretrained_model(resnet_base, input_shape, num_classes)\n",
        "resnet_history_sampled = train_and_evaluate_model(resnet_model_sampled, \"ResNet101 (Sampled Dataset)\", x_train_sampled, y_train_sampled, x_test_sampled, y_test_sampled, train_datagen, class_weights_dict_sampled)"
      ],
      "metadata": {
        "id": "Q_GI6trmX8Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 Plot individual models\n",
        "models = {\n",
        "    \"Custom CNN\": custom_history_full,\n",
        "    \"Custom CNN_sampled\": custom_history_sampled,\n",
        "    \"VGG16\": vgg16_history_full,\n",
        "    \"VGG16_sampled\": vgg16_history_sampled,\n",
        "    \"DenseNet201\": densenet_history_full,\n",
        "    \"DenseNet201_sampled\": densenet_history_sampled,\n",
        "    \"ResNet101\": resnet_history_full,\n",
        "    \"ResNet101_sampled\": resnet_history_sampled\n",
        "}\n",
        "\n",
        "for model_name, history in models.items():\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} - Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} - Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iiitT_i5R_p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Predict and Display Images\n",
        "# Function to display predictions for 5 random images\n",
        "def display_predictions(model, x_test, y_test, labels, num_images=5):\n",
        "    indices = np.random.choice(len(x_test), num_images, replace=False)\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, idx in enumerate(indices):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        img = x_test[idx]\n",
        "        true_label = labels[np.argmax(y_test[idx])]\n",
        "        pred_label = labels[np.argmax(model.predict(img[np.newaxis, ...]))]\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "print(\"Predictions for Full Dataset\")\n",
        "display_predictions(custom_model_full, x_test_full, y_test_full, labels, num_images=5)\n",
        "\n",
        "print(\"Predictions for Sampled Dataset\")\n",
        "display_predictions(custom_model_sampled, x_test_sampled, y_test_sampled, labels, num_images=5)\n"
      ],
      "metadata": {
        "id": "4Ty8i6C2R_mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for each individual model\n",
        "vgg_preds_full = np.argmax(vgg16_model_full.predict(x_test_full), axis=1)\n",
        "resnet_preds_full = np.argmax(resnet_model_full.predict(x_test_full), axis=1)\n",
        "custom_preds_full = np.argmax(custom_model_full.predict(x_test_full), axis=1)\n",
        "densenet_preds_full = np.argmax(densenet_model_full.predict(x_test_full), axis=1)\n",
        "\n",
        "vgg_preds_sampled = np.argmax(vgg16_model_sampled.predict(x_test_sampled), axis=1)\n",
        "resnet_preds_sampled = np.argmax(resnet_model_sampled.predict(x_test_sampled), axis=1)\n",
        "custom_preds_sampled = np.argmax(custom_model_sampled.predict(x_test_sampled), axis=1)\n",
        "densenet_preds_sampled = np.argmax(densenet_model_sampled.predict(x_test_sampled), axis=1)\n",
        "\n",
        "# True labels\n",
        "y_true_full = np.argmax(y_test_full, axis=1)\n",
        "y_true_sampled = np.argmax(y_test_sampled, axis=1)\n",
        "\n",
        "# Ensemble model predictions (majority voting)\n",
        "ensemble_preds_full = []\n",
        "for i in range(len(vgg_preds_full)):\n",
        "    preds = [vgg_preds_full[i], resnet_preds_full[i], custom_preds_full[i]]\n",
        "    ensemble_preds_full.append(max(set(preds), key=preds.count))\n",
        "\n",
        "ensemble_preds_sampled = []\n",
        "for i in range(len(vgg_preds_sampled)):\n",
        "    preds = [vgg_preds_sampled[i], resnet_preds_sampled[i], custom_preds_sampled[i]]\n",
        "    ensemble_preds_sampled.append(max(set(preds), key=preds.count))\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return {\"Model\": model_name, \"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1}\n",
        "\n",
        "# Evaluate models for the full dataset\n",
        "results_full = []\n",
        "results_full.append(evaluate_model(y_true_full, vgg_preds_full, \"VGG16\"))\n",
        "results_full.append(evaluate_model(y_true_full, resnet_preds_full, \"ResNet101\"))\n",
        "results_full.append(evaluate_model(y_true_full, custom_preds_full, \"Custom CNN\"))\n",
        "results_full.append(evaluate_model(y_true_full, densenet_preds_full, \"DenseNet201\"))\n",
        "\n",
        "\n",
        "# Evaluate models for the sampled dataset\n",
        "results_sampled = []\n",
        "results_sampled.append(evaluate_model(y_true_sampled, vgg_preds_sampled, \"VGG16\"))\n",
        "results_sampled.append(evaluate_model(y_true_sampled, resnet_preds_sampled, \"ResNet101\"))\n",
        "results_sampled.append(evaluate_model(y_true_sampled, custom_preds_sampled, \"Custom CNN\"))\n",
        "results_sampled.append(evaluate_model(y_true_sampled, densenet_preds_sampled, \"DenseNet201\"))\n",
        "\n",
        "\n",
        "# Convert results to DataFrames for comparison\n",
        "results_full_df = pd.DataFrame(results_full)\n",
        "results_sampled_df = pd.DataFrame(results_sampled)\n",
        "\n",
        "# Bar plot for the full dataset\n",
        "results_full_df.set_index(\"Model\").plot(kind='bar', figsize=(10, 6))\n",
        "plt.title(\"Model Performance Comparison (Full Dataset)\")\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Performance Metrics\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bar plot for the sampled dataset\n",
        "results_sampled_df.set_index(\"Model\").plot(kind='bar', figsize=(10, 6))\n",
        "plt.title(\"Model Performance Comparison (Sampled Dataset)\")\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Performance Metrics\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vOQQYj0LvTFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rP-vIWWT3vx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdUddUoC4Ixp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1sWp4Sd5d2qO91pY6Pxns6ewZItK6yvFO",
      "authorship_tag": "ABX9TyNy3XpgE+8osHeI86AvwviT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}